{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7JxGQerhz0n"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import speech_recognition as sr\n",
        "import pyttsx3\n",
        "import random\n",
        "import sqlite3\n",
        "import time\n",
        "import spacy\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from PyPDF2 import PdfReader\n",
        "import docx\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ====== Step 1: Silence Huggingface Hub Warning ======\n",
        "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
        "\n",
        "# ====== Step 2: Load spaCy Model ======\n",
        "@st.cache_resource\n",
        "def load_spacy_model():\n",
        "    return spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "nlp = load_spacy_model()\n",
        "\n",
        "# ====== Step 3: Load Siamese Network ======\n",
        "def build_siamese_network():\n",
        "    # Input layers\n",
        "    input_1 = Input(shape=(768,))  # Input shape based on Sentence-BERT embeddings\n",
        "    input_2 = Input(shape=(768,))\n",
        "\n",
        "    # Lambda layer to calculate the L1 distance\n",
        "    l1_distance = Lambda(lambda embeddings: K.abs(embeddings[0] - embeddings[1]))([input_1, input_2])\n",
        "\n",
        "    # Dense layer to classify whether the pair is similar\n",
        "    similarity = Dense(1, activation='sigmoid')(l1_distance)\n",
        "\n",
        "    # Build model\n",
        "    siamese_model = Model(inputs=[input_1, input_2], outputs=similarity)\n",
        "    siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return siamese_model\n",
        "\n",
        "siamese_model = build_siamese_network()\n",
        "\n",
        "# ====== Step 4: Database Functions ======\n",
        "def load_questions_from_db(stream, level):\n",
        "    conn = sqlite3.connect('interview_questions.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    c.execute('''\n",
        "        SELECT question, expected_answer\n",
        "        FROM questions\n",
        "        WHERE stream = ? AND level = ?\n",
        "    ''', (stream, level))\n",
        "\n",
        "    questions = c.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    return questions\n",
        "\n",
        "# ====== Step 5: Resume Text Extraction Functions ======\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    reader = PdfReader(pdf_file)\n",
        "    text = ''\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            text += page_text + '\\n'\n",
        "    return text\n",
        "\n",
        "def extract_text_from_docx(docx_file):\n",
        "    doc = docx.Document(docx_file)\n",
        "    full_text = []\n",
        "    for para in doc.paragraphs:\n",
        "        full_text.append(para.text)\n",
        "    return '\\n'.join(full_text)\n",
        "\n",
        "# ====== Step 6: Determine Stream from Resume ======\n",
        "def determine_stream_from_resume(resume_text):\n",
        "    resume_text_lower = resume_text.lower()\n",
        "    if 'python' in resume_text_lower:\n",
        "        return 'Python'\n",
        "    elif 'java' in resume_text_lower:\n",
        "        return 'Java'\n",
        "    elif 'machine learning' in resume_text_lower:\n",
        "        return 'Machine Learning'\n",
        "    elif 'data science' in resume_text_lower:\n",
        "        return 'Data Science'\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# ====== Step 7: Initialize Streamlit App ======\n",
        "st.title(\"Mock Interview Assistant\")\n",
        "\n",
        "# ====== Step 8: Sidebar - Interview Settings ======\n",
        "st.sidebar.header(\"Interview Settings\")\n",
        "question_source = st.sidebar.radio(\n",
        "    \"Would you like to be asked questions based on your resume or manually select a stream?\",\n",
        "    (\"Resume-Based\", \"Manually Select Stream\")\n",
        ")\n",
        "\n",
        "difficulty_level = st.sidebar.selectbox(\"Select Difficulty Level\", [\"Beginner\", \"Intermediate\", \"Advanced\"])\n",
        "\n",
        "resume_text = ''\n",
        "if question_source == \"Resume-Based\":\n",
        "    resume_file = st.sidebar.file_uploader(\"Upload your resume (PDF or DOCX)\", type=[\"pdf\", \"docx\"])\n",
        "    if resume_file is not None:\n",
        "        if resume_file.type == \"application/pdf\":\n",
        "            resume_text = extract_text_from_pdf(resume_file)\n",
        "        elif resume_file.type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\":\n",
        "            resume_text = extract_text_from_docx(resume_file)\n",
        "\n",
        "        st.write(\"### Extracted Resume Text:\")\n",
        "        st.write(resume_text[:1000] + ('...' if len(resume_text) > 1000 else ''))\n",
        "\n",
        "        stream = determine_stream_from_resume(resume_text)\n",
        "        if stream:\n",
        "            st.write(f\"*Detected stream:* {stream}\")\n",
        "        else:\n",
        "            st.write(\"Could not detect a stream based on your resume. Please select manually.\")\n",
        "            stream = None\n",
        "    else:\n",
        "        stream = None\n",
        "else:\n",
        "    stream = st.sidebar.selectbox(\"Stream\", [\"Python\", \"Java\", \"C++\", \"JavaScript\", \"Data Science\", \"Machine Learning\"])\n",
        "\n",
        "st.write(\"Welcome to the *Mock Interview Assistant*. Prepare for your interview by answering questions.\")\n",
        "\n",
        "# ====== Step 9: Initialize Session State ======\n",
        "if 'current_question' not in st.session_state:\n",
        "    st.session_state['current_question'] = None\n",
        "    st.session_state['expected_answer'] = None\n",
        "    st.session_state['question_asked'] = False\n",
        "    st.session_state['user_answer'] = \"\"\n",
        "    st.session_state['feedback'] = \"\"\n",
        "    st.session_state['start_time'] = None\n",
        "    st.session_state['similarity'] = 0\n",
        "    st.session_state['response_time'] = 0\n",
        "\n",
        "# ====== Step 10: Function to Generate a Random Question ======\n",
        "def generate_question_from_db(stream, level):\n",
        "    questions = load_questions_from_db(stream, level)\n",
        "    if questions:\n",
        "        return random.choice(questions)\n",
        "    else:\n",
        "        st.error(\"No questions available for the selected stream and level.\")\n",
        "        return None, None\n",
        "\n",
        "# ====== Step 11: Function to Get Sentence Embeddings (Sentence-BERT) ======\n",
        "sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "def get_sentence_embeddings(text):\n",
        "    return sentence_model.encode(text)\n",
        "\n",
        "# ====== Step 12: Similarity with Siamese Network ======\n",
        "def calculate_similarity_siamese(user_answer, expected_answer):\n",
        "    # Encode both user answer and expected answer\n",
        "    user_embedding = get_sentence_embeddings(user_answer).reshape(1, -1)\n",
        "    expected_embedding = get_sentence_embeddings(expected_answer).reshape(1, -1)\n",
        "\n",
        "    # Predict similarity using the Siamese model\n",
        "    similarity = siamese_model.predict([user_embedding, expected_embedding])[0][0]\n",
        "\n",
        "    return similarity\n",
        "\n",
        "# ====== Step 13: Ask Question Section ======\n",
        "st.header(\"Interview Question\")\n",
        "if st.button(\"Ask Question\"):\n",
        "    if stream and difficulty_level:\n",
        "        question_data = generate_question_from_db(stream, difficulty_level)\n",
        "        if question_data:\n",
        "            st.session_state['current_question'], st.session_state['expected_answer'] = question_data\n",
        "            st.session_state['question_asked'] = True\n",
        "            st.session_state['start_time'] = time.time()\n",
        "            st.write(\"### Question:\")\n",
        "            st.write(st.session_state['current_question'])\n",
        "\n",
        "            engine = pyttsx3.init()\n",
        "            engine.say(st.session_state['current_question'])\n",
        "            engine.runAndWait()\n",
        "\n",
        "# ====== Step 14: Speech Input Section ======\n",
        "st.header(\"Speech Input\")\n",
        "if st.session_state['question_asked'] and st.button(\"Record Speech\"):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.Microphone() as source:\n",
        "        st.write(\"Recording... Please speak clearly.\")\n",
        "        try:\n",
        "            audio = recognizer.listen(source, timeout=5)\n",
        "            st.write(\"Processing...\")\n",
        "            user_answer = recognizer.recognize_google(audio)\n",
        "            st.session_state['user_answer'] = user_answer\n",
        "            st.text_area(\"Your Answer:\", st.session_state['user_answer'])\n",
        "\n",
        "            # Calculate response time\n",
        "            st.session_state['response_time'] = time.time() - st.session_state['start_time']\n",
        "\n",
        "            # Calculate similarity using Siamese network\n",
        "            expected_answer = st.session_state['expected_answer']\n",
        "            similarity = calculate_similarity_siamese(user_answer, expected_answer)\n",
        "            st.session_state['similarity'] = similarity\n",
        "            st.write(f\"*Siamese Network Similarity Score:* {similarity * 100:.2f}%\")\n",
        "\n",
        "            # Provide feedback based on similarity\n",
        "            if similarity > 0.75:\n",
        "                st.session_state['feedback'] = \"Good answer! Your response closely matches the expected answer.\"\n",
        "            else:\n",
        "                st.session_state['feedback'] = \"Your answer could be improved. Try including more relevant details.\"\n",
        "\n",
        "            st.write(\"### Feedback:\")\n",
        "            st.write(st.session_state['feedback'])\n",
        "\n",
        "        except sr.WaitTimeoutError:\n",
        "            st.error(\"Listening timed out. Please try again.\")\n",
        "        except sr.UnknownValueError:\n",
        "            st.error(\"Could not understand the audio. Please try again.\")\n",
        "        except sr.RequestError:\n",
        "            st.error(\"Speech recognition service is unavailable.\")\n",
        "\n",
        "# ====== Step 15: Performance Metrics Section ======\n",
        "st.header(\"Performance Metrics\")\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.metric(\"Similarity Score\", f\"{st.session_state['similarity'] * 100:.2f}%\")\n",
        "    st.metric(\"Response Time (s)\", f\"{st.session_state['response_time']:.2f}\")"
      ]
    }
  ]
}